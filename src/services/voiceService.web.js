/**
 * Web ç«¯è¯­éŸ³æœåŠ¡
 * ä½¿ç”¨æµè§ˆå™¨ SpeechRecognition å’Œ SpeechSynthesis API
 */

const getSpeechRecognitionCtor = () => {
  if (typeof window === 'undefined') {
    return null;
  }
  return window.SpeechRecognition || window.webkitSpeechRecognition || null;
};

let recognitionInstance = null;
let recognitionPromise = null;
let resolveRecognition = null;
let rejectRecognition = null;
let lastTranscript = '';

/**
 * æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒè¯­éŸ³è¯†åˆ«
 * @returns {boolean} æ˜¯å¦æ”¯æŒ
 */
const isRecognitionSupported = () => Boolean(getSpeechRecognitionCtor());

/**
 * è¯·æ±‚è¯­éŸ³æƒé™ï¼ˆWeb Speech æ— æ˜¾å¼æƒé™ï¼Œåªæ£€æŸ¥æ”¯æŒæ€§ï¼‰
 * @returns {Promise<boolean>} æ˜¯å¦å¯ç”¨
 */
export const requestAudioPermission = async () => isRecognitionSupported();

/**
 * æ£€æŸ¥è¯­éŸ³æƒé™
 * @returns {Promise<string>} æƒé™çŠ¶æ€
 */
export const checkAudioPermission = async () => (isRecognitionSupported() ? 'granted' : 'denied');

/**
 * å¼€å§‹è¯­éŸ³å½•åˆ¶/è¯†åˆ«
 * @returns {Promise<{success: boolean, error?: string}>}
 */
export const startRecording = async () => {
  const SpeechRecognition = getSpeechRecognitionCtor();

  if (!SpeechRecognition) {
    return {
      success: false,
      error: 'å½“å‰æµè§ˆå™¨æš‚ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½',
    };
  }

  if (recognitionInstance) {
    recognitionInstance.stop();
    recognitionInstance = null;
  }

  recognitionInstance = new SpeechRecognition();
  recognitionInstance.lang = 'zh-CN';
  recognitionInstance.interimResults = false;
  recognitionInstance.continuous = false;
  lastTranscript = '';

  recognitionPromise = new Promise((resolve, reject) => {
    resolveRecognition = resolve;
    rejectRecognition = reject;
  });

  recognitionInstance.onresult = (event) => {
    const transcript = Array.from(event.results)
      .map((result) => result[0]?.transcript || '')
      .join(' ')
      .trim();

    lastTranscript = transcript;
    resolveRecognition?.({
      transcript,
      confidence: event.results?.[0]?.[0]?.confidence ?? 0,
    });
  };

  recognitionInstance.onerror = (event) => {
    const errorMessage = event?.error || event?.message || 'è¯­éŸ³è¯†åˆ«å‘ç”Ÿé”™è¯¯';
    rejectRecognition?.(new Error(errorMessage));
  };

  recognitionInstance.onend = () => {
    if (recognitionInstance) {
      recognitionInstance = null;
    }
    if (resolveRecognition && !lastTranscript) {
      resolveRecognition({ transcript: '', confidence: 0 });
    }
  };

  try {
    recognitionInstance.start();
    return { success: true };
  } catch (error) {
    recognitionInstance = null;
    resolveRecognition = null;
    rejectRecognition = null;
    recognitionPromise = null;
    return {
      success: false,
      error: error?.message || 'è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥',
    };
  }
};

/**
 * åœæ­¢è¯­éŸ³å½•åˆ¶å¹¶è¿”å›è¯†åˆ«ç»“æœ
 * @returns {Promise<{success: boolean, text?: string, uri: null, confidence?: number, error?: string}>}
 */
export const stopRecording = async () => {
  if (!recognitionPromise) {
    return {
      success: false,
      error: 'æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„è¯­éŸ³è¯†åˆ«',
    };
  }

  try {
    if (recognitionInstance) {
      recognitionInstance.stop();
    }

    const result = await recognitionPromise;
    recognitionInstance = null;
    recognitionPromise = null;
    resolveRecognition = null;
    rejectRecognition = null;

    if (!result?.transcript) {
      return {
        success: false,
        error: 'æœªæ•è·åˆ°è¯­éŸ³å†…å®¹',
      };
    }

    return {
      success: true,
      text: result.transcript,
      uri: null,
      confidence: result?.confidence ?? 0,
    };
  } catch (error) {
    recognitionInstance = null;
    recognitionPromise = null;
    resolveRecognition = null;
    rejectRecognition = null;
    return {
      success: false,
      error: error?.message || 'è¯­éŸ³è¯†åˆ«å¤±è´¥',
    };
  }
};

/**
 * å–æ¶ˆå½“å‰è¯­éŸ³è¯†åˆ«
 * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸå–æ¶ˆ
 */
export const cancelRecording = async () => {
  if (!recognitionInstance) {
    return true;
  }
  try {
    recognitionInstance.abort();
  } catch (error) {
    console.warn('[voiceService.web] å–æ¶ˆè¯†åˆ«å¤±è´¥:', error);
  }
  recognitionInstance = null;
  recognitionPromise = null;
  resolveRecognition = null;
  rejectRecognition = null;
  return true;
};

/**
 * è·å–å½•éŸ³çŠ¶æ€
 * @returns {Promise<{isRecording: boolean}>}
 */
export const getRecordingStatus = async () => ({
  isRecording: Boolean(recognitionInstance),
});

/**
 * è¯­éŸ³è¯†åˆ«åˆ°æ–‡æœ¬ï¼ˆç›´æ¥è¿”å›ç¼“å­˜ç»“æœï¼‰
 * @returns {Promise<{success: boolean, text: string, isMock: boolean}>}
 */
export const speechToText = async () => {
  if (!lastTranscript) {
    return {
      success: false,
      error: 'æš‚æœªæ•è·è¯­éŸ³å†…å®¹',
    };
  }
  return {
    success: true,
    text: lastTranscript,
    isMock: false,
  };
};

/**
 * æ ¹æ®å¿«æ·åŠŸèƒ½ç±»å‹å¤„ç†è¯­éŸ³ï¼ˆå¤ç”¨è¯†åˆ«ç»“æœï¼‰
 * @param {null} _ignoredUri æœªä½¿ç”¨çš„éŸ³é¢‘ URI
 * @param {string} actionType åŠŸèƒ½ç±»å‹
 * @returns {Promise<Object>} å¤„ç†åçš„è¯­éŸ³ä¿¡æ¯
 */
export const processVoiceWithAction = async (_ignoredUri, actionType) => {
  const result = await speechToText();
  if (!result.success) {
    return {
      success: false,
      error: result.error,
    };
  }

  const actionMap = {
    route: {
      type: 'route',
      action: 'æ­£åœ¨ä¸ºæ‚¨è§„åˆ’è·¯çº¿...',
      icon: 'ğŸš¶',
    },
    location: {
      type: 'location',
      action: 'æ­£åœ¨ä¸ºæ‚¨æŸ¥æ‰¾ä½ç½®...',
      icon: 'ğŸ“',
    },
    image: {
      type: 'image',
      action: 'è¯·ä¸Šä¼ ç›¸å…³å›¾ç‰‡...',
      icon: 'ğŸ“·',
    },
    voice: {
      type: 'voice',
      action: 'æ­£åœ¨ä¸ºæ‚¨è®²è§£...',
      icon: 'ğŸ”Š',
    },
  };

  const fallback = {
    type: 'default',
    action: 'å¤„ç†ä¸­...',
    icon: 'ğŸ’¬',
  };

  return {
    success: true,
    text: result.text,
    confidence: 0.9,
    ...(actionMap[actionType] || fallback),
  };
};

let activeUtterance = null;

/**
 * æ–‡æœ¬è½¬è¯­éŸ³æ’­æ”¾
 * @param {string} text æ–‡æœ¬å†…å®¹
 * @returns {Promise<{success: boolean, error?: string}>}
 */
export const textToSpeech = async (text) => {
  if (typeof window === 'undefined' || !window.speechSynthesis) {
    return {
      success: false,
      error: 'å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³æ’­æ”¾',
    };
  }

  try {
    if (activeUtterance) {
      window.speechSynthesis.cancel();
      activeUtterance = null;
    }

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'zh-CN';
    utterance.rate = 1.0;
    utterance.pitch = 1.0;
    activeUtterance = utterance;

    window.speechSynthesis.speak(utterance);
    return { success: true };
  } catch (error) {
    console.warn('[voiceService.web] è¯­éŸ³æ’­æ”¾å¤±è´¥:', error);
    return {
      success: false,
      error: error?.message || 'è¯­éŸ³æ’­æ”¾å¤±è´¥',
    };
  }
};

/**
 * åœæ­¢è¯­éŸ³æ’­æ”¾
 * @returns {Promise<boolean>} æ˜¯å¦æˆåŠŸåœæ­¢
 */
export const stopPlayback = async () => {
  if (typeof window === 'undefined' || !window.speechSynthesis) {
    return false;
  }
  window.speechSynthesis.cancel();
  activeUtterance = null;
  return true;
};

/**
 * æ¸…ç†èµ„æº
 * @returns {Promise<void>}
 */
export const cleanup = async () => {
  await cancelRecording();
  await stopPlayback();
};

export default {
  requestAudioPermission,
  checkAudioPermission,
  startRecording,
  stopRecording,
  cancelRecording,
  getRecordingStatus,
  speechToText,
  processVoiceWithAction,
  textToSpeech,
  stopPlayback,
  cleanup,
};


