/**
 * è¯­éŸ³æœåŠ¡
 * å¤„ç†è¯­éŸ³å½•éŸ³ã€è¯†åˆ«ã€æ’­æ”¾å’Œè½¬æ¢
 */

import { Audio } from 'expo-av';

// APIé…ç½®
const VOICE_API_CONFIG = {
  baseURL: process.env.VOICE_API_URL || 'https://your-voice-api-endpoint.com',
  timeout: 30000,
};

// å…¨å±€å½•éŸ³å¯¹è±¡
let recording = null;
let sound = null;

/**
 * åˆå§‹åŒ–éŸ³é¢‘æ¨¡å¼
 */
const initAudioMode = async () => {
  try {
    await Audio.setAudioModeAsync({
      allowsRecordingIOS: true,
      playsInSilentModeIOS: true,
      staysActiveInBackground: false,
      shouldDuckAndroid: true,
      playThroughEarpieceAndroid: false,
    });
  } catch (error) {
    console.error('åˆå§‹åŒ–éŸ³é¢‘æ¨¡å¼å¤±è´¥:', error);
  }
};

/**
 * è¯·æ±‚å½•éŸ³æƒé™
 * @returns {Promise<boolean>} æ˜¯å¦è·å¾—æƒé™
 */
export const requestAudioPermission = async () => {
  try {
    const { status } = await Audio.requestPermissionsAsync();
    
    if (status === 'granted') {
      await initAudioMode();
      return true;
    }
    
    console.warn('å½•éŸ³æƒé™è¢«æ‹’ç»');
    return false;
  } catch (error) {
    console.error('è¯·æ±‚å½•éŸ³æƒé™å¤±è´¥:', error);
    return false;
  }
};

/**
 * æ£€æŸ¥å½•éŸ³æƒé™çŠ¶æ€
 * @returns {Promise<string>} æƒé™çŠ¶æ€
 */
export const checkAudioPermission = async () => {
  try {
    const { status } = await Audio.getPermissionsAsync();
    return status;
  } catch (error) {
    console.error('æ£€æŸ¥å½•éŸ³æƒé™å¤±è´¥:', error);
    return 'undetermined';
  }
};

/**
 * å¼€å§‹å½•éŸ³
 * @param {Object} options - å½•éŸ³é€‰é¡¹
 * @returns {Promise<Object>} å½•éŸ³å¯¹è±¡å’ŒçŠ¶æ€
 */
export const startRecording = async (options = {}) => {
  try {
    // æ£€æŸ¥æƒé™
    const hasPermission = await requestAudioPermission();
    if (!hasPermission) {
      return {
        success: false,
        error: 'æ²¡æœ‰å½•éŸ³æƒé™ï¼Œè¯·åœ¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£',
      };
    }

    // åœæ­¢ä¹‹å‰çš„å½•éŸ³
    if (recording) {
      await stopRecording();
    }

    // é…ç½®å½•éŸ³é€‰é¡¹
    const recordingOptions = {
      ...Audio.RecordingOptionsPresets.HIGH_QUALITY,
      ...options,
    };

    // åˆ›å»ºå½•éŸ³å¯¹è±¡
    const { recording: newRecording } = await Audio.Recording.createAsync(
      recordingOptions
    );

    recording = newRecording;

    return {
      success: true,
      recording: newRecording,
    };
  } catch (error) {
    console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error);
    return {
      success: false,
      error: error.message || 'å½•éŸ³å¯åŠ¨å¤±è´¥',
    };
  }
};

/**
 * åœæ­¢å½•éŸ³
 * @returns {Promise<Object>} å½•éŸ³URIã€æ—¶é•¿å’ŒçŠ¶æ€
 */
export const stopRecording = async () => {
  try {
    if (!recording) {
      return {
        success: false,
        error: 'æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„å½•éŸ³',
      };
    }

    await recording.stopAndUnloadAsync();
    const uri = recording.getURI();
    const status = await recording.getStatusAsync();

    const result = {
      success: true,
      uri,
      duration: status.durationMillis,
      size: status.metering,
    };

    recording = null;

    return result;
  } catch (error) {
    console.error('åœæ­¢å½•éŸ³å¤±è´¥:', error);
    recording = null;
    return {
      success: false,
      error: error.message || 'åœæ­¢å½•éŸ³å¤±è´¥',
    };
  }
};

/**
 * å–æ¶ˆå½•éŸ³
 * @returns {Promise<boolean>} æ“ä½œç»“æœ
 */
export const cancelRecording = async () => {
  try {
    if (recording) {
      await recording.stopAndUnloadAsync();
      recording = null;
    }
    return true;
  } catch (error) {
    console.error('å–æ¶ˆå½•éŸ³å¤±è´¥:', error);
    recording = null;
    return false;
  }
};

/**
 * è·å–å½•éŸ³çŠ¶æ€
 * @returns {Promise<Object|null>} å½•éŸ³çŠ¶æ€
 */
export const getRecordingStatus = async () => {
  try {
    if (!recording) {
      return null;
    }
    return await recording.getStatusAsync();
  } catch (error) {
    console.error('è·å–å½•éŸ³çŠ¶æ€å¤±è´¥:', error);
    return null;
  }
};

/**
 * å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡å­—
 * @param {string} audioUri - éŸ³é¢‘æ–‡ä»¶URI
 * @param {Object} options - è¯†åˆ«é€‰é¡¹
 * @returns {Promise<Object>} è¯†åˆ«ç»“æœ
 */
export const speechToText = async (audioUri, options = {}) => {
  try {
    const formData = new FormData();
    formData.append('audio', {
      uri: audioUri,
      type: 'audio/m4a',
      name: 'recording.m4a',
    });

    // æ·»åŠ é¢å¤–å‚æ•°
    if (options.language) {
      formData.append('language', options.language);
    }
    if (options.actionType) {
      formData.append('actionType', options.actionType);
    }

    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), VOICE_API_CONFIG.timeout);

    const response = await fetch(`${VOICE_API_CONFIG.baseURL}/speech-to-text`, {
      method: 'POST',
      body: formData,
      signal: controller.signal,
      headers: {
        'Accept': 'application/json',
      },
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      throw new Error(`è¯­éŸ³è¯†åˆ«APIé”™è¯¯: ${response.status}`);
    }

    const data = await response.json();
    
    return {
      success: true,
      text: data.text,
      confidence: data.confidence || 0,
      language: data.language,
    };
  } catch (error) {
    console.error('è¯­éŸ³è½¬æ–‡å­—å¤±è´¥:', error);
    
    // å¼€å‘ç¯å¢ƒè¿”å›æ¨¡æ‹Ÿæ•°æ®
    if (__DEV__) {
      return {
        success: true,
        text: getMockRecognitionText(options.actionType),
        confidence: 0.95,
        isMock: true,
      };
    }
    
    return {
      success: false,
      error: error.message || 'è¯­éŸ³è¯†åˆ«å¤±è´¥',
    };
  }
};

/**
 * ç”Ÿæˆæ¨¡æ‹Ÿè¯†åˆ«æ–‡æœ¬ï¼ˆå¼€å‘é˜¶æ®µä½¿ç”¨ï¼‰
 * @param {string} actionType - å¿«æ·åŠŸèƒ½ç±»å‹
 * @returns {string} æ¨¡æ‹Ÿæ–‡æœ¬
 */
const getMockRecognitionText = (actionType) => {
  const mockTexts = {
    route: 'ä»å›¾ä¹¦é¦†åˆ°é£Ÿå ‚æ€ä¹ˆèµ°ï¼Ÿ',
    location: 'æœ€è¿‘çš„å’–å•¡å…åœ¨å“ªé‡Œï¼Ÿ',
    image: 'è¿™æ˜¯ä»€ä¹ˆå»ºç­‘ï¼Ÿ',
    voice: 'ç»™æˆ‘è®²è®²è¿™ä¸ªåœ°æ–¹çš„å†å²',
    default: 'ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹æ ¡å›­ä¿¡æ¯',
  };

  return mockTexts[actionType] || mockTexts.default;
};

/**
 * æ–‡å­—è½¬è¯­éŸ³å¹¶æ’­æ”¾
 * @param {string} text - è¦è½¬æ¢çš„æ–‡å­—
 * @param {Object} options - è¯­éŸ³é€‰é¡¹
 * @returns {Promise<Object>} æ’­æ”¾ç»“æœ
 */
export const textToSpeech = async (text, options = {}) => {
  try {
    // åœæ­¢ä¹‹å‰çš„æ’­æ”¾
    if (sound) {
      await sound.stopAsync();
      await sound.unloadAsync();
      sound = null;
    }

    const response = await fetch(`${VOICE_API_CONFIG.baseURL}/text-to-speech`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        text,
        voiceType: options.voiceType || 'female',
        language: options.language || 'zh-CN',
        speed: options.speed || 1.0,
      }),
    });

    if (!response.ok) {
      throw new Error('æ–‡å­—è½¬è¯­éŸ³å¤±è´¥');
    }

    const data = await response.json();
    
    // æ’­æ”¾éŸ³é¢‘
    const { sound: newSound } = await Audio.Sound.createAsync(
      { uri: data.audioUrl },
      { shouldPlay: true }
    );

    sound = newSound;

    return {
      success: true,
      sound: newSound,
    };
  } catch (error) {
    console.error('æ–‡å­—è½¬è¯­éŸ³å¤±è´¥:', error);
    return {
      success: false,
      error: error.message || 'è¯­éŸ³æ’­æ”¾å¤±è´¥',
    };
  }
};

/**
 * åœæ­¢è¯­éŸ³æ’­æ”¾
 * @returns {Promise<boolean>} æ“ä½œç»“æœ
 */
export const stopPlayback = async () => {
  try {
    if (sound) {
      await sound.stopAsync();
      await sound.unloadAsync();
      sound = null;
    }
    return true;
  } catch (error) {
    console.error('åœæ­¢æ’­æ”¾å¤±è´¥:', error);
    return false;
  }
};

/**
 * å¤„ç†å¸¦æœ‰ä¸Šä¸‹æ–‡çš„è¯­éŸ³è¾“å…¥
 * @param {string} audioUri - éŸ³é¢‘URI
 * @param {string} actionType - åŠŸèƒ½ç±»å‹
 * @param {Object} context - ä¸Šä¸‹æ–‡ä¿¡æ¯
 * @returns {Promise<Object>} å¤„ç†ç»“æœ
 */
export const processVoiceWithAction = async (audioUri, actionType, context = {}) => {
  try {
    // è¯­éŸ³è¯†åˆ«
    const sttResult = await speechToText(audioUri, { actionType });
    
    if (!sttResult.success) {
      return {
        success: false,
        error: sttResult.error,
      };
    }

    const text = sttResult.text;
    const actionMap = {
      route: {
        type: 'route',
        action: 'æ­£åœ¨ä¸ºæ‚¨è§„åˆ’è·¯çº¿...',
        icon: 'ğŸš¶',
      },
      location: {
        type: 'location',
        action: 'æ­£åœ¨ä¸ºæ‚¨æŸ¥æ‰¾ä½ç½®...',
        icon: 'ğŸ“',
      },
      image: {
        type: 'image',
        action: 'è¯·æ‹æ‘„ç…§ç‰‡...',
        icon: 'ğŸ“·',
      },
      voice: {
        type: 'voice',
        action: 'æ­£åœ¨ä¸ºæ‚¨è®²è§£...',
        icon: 'ğŸ”Š',
      },
    };

    const actionInfo = actionMap[actionType] || {
      type: 'default',
      action: 'æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...',
      icon: 'ğŸ’¬',
    };

    console.log(`å¤„ç†${actionInfo.type}è¯­éŸ³:`, text);

    return {
      success: true,
      text,
      confidence: sttResult.confidence,
      ...actionInfo,
      context,
    };
  } catch (error) {
    console.error('å¤„ç†è¯­éŸ³å¤±è´¥:', error);
    return {
      success: false,
      error: error.message || 'è¯­éŸ³å¤„ç†å¤±è´¥',
    };
  }
};

/**
 * æ¸…ç†æ‰€æœ‰éŸ³é¢‘èµ„æº
 * @returns {Promise<void>}
 */
export const cleanup = async () => {
  try {
    await cancelRecording();
    await stopPlayback();
  } catch (error) {
    console.error('æ¸…ç†éŸ³é¢‘èµ„æºå¤±è´¥:', error);
  }
};

export default {
  requestAudioPermission,
  checkAudioPermission,
  startRecording,
  stopRecording,
  cancelRecording,
  getRecordingStatus,
  speechToText,
  textToSpeech,
  stopPlayback,
  processVoiceWithAction,
  cleanup,
};
